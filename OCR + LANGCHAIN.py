# -*- coding: utf-8 -*-
"""Correcao.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jz5nlyo0Mil2ncxjji2iMo-bBkUGLkJy
"""

# --- CÉLULA 1: INSTALAR O OLLAMA ---

# Baixa o script de instalação do Ollama
!curl -fsSL https://ollama.com/install.sh | sh

print("Ollama instalado com sucesso!")

# --- CÉLULA 2: INICIAR O SERVIDOR E BAIXAR O MODELO ---
import os
import time
from google.colab import files

# O '&' no final executa o processo em segundo plano.
os.system('ollama serve &')

# Aguarda 5 segundos para o servidor iniciar completamente.
# Usamos time.sleep() para evitar o conflito com o event loop do Colab.
print("Aguardando o servidor Ollama iniciar...")
time.sleep(5)
print("Servidor pronto.")

# Baixa o modelo desejado (ex: llama3:8b)
# Isso pode levar alguns minutos dependendo do tamanho do modelo e da conexão do Colab
!ollama pull llama3:8b

print("\nModelo Llama 3 baixado.")

# --- CÉLULA 3: INSTALAR O LANGCHAIN ---

!pip install langchain langchain_community langchain_core

print("Bibliotecas do LangChain instaladas.")

from PIL import Image
import pytesseract
from langchain.llms import Ollama
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Caminho da imagem com pergunta + resposta
caminho_imagem = "/content/resposta_aluno.jpg"

# OCR
def extrair_texto_da_imagem(caminho_imagem):
    imagem = Image.open(caminho_imagem)
    texto = pytesseract.image_to_string(imagem, lang='por')
    return texto.strip()

texto_extraido = extrair_texto_da_imagem(caminho_imagem)

# Gabarito (tema: Guerra Fria)
gabaritos = {
    "O que foi a Guerra Fria?": "Foi um conflito ideológico, político e estratégico entre os EUA e a URSS entre 1947 e 1991, sem confrontos diretos entre eles.",
    "Qual era o objetivo da Doutrina Truman?": "Conter o avanço do comunismo, oferecendo apoio a países ameaçados pela influência soviética.",
    "O que representava o Muro de Berlim?": "A divisão do mundo entre capitalismo e socialismo durante a Guerra Fria.",
    "Qual foi a importância do Plano Marshall?": "Reconstruir a Europa Ocidental e evitar o avanço do socialismo, fortalecendo a influência dos EUA.",
    "Quais foram os principais conflitos indiretos da Guerra Fria?": "Guerra da Coreia, Guerra do Vietnã e a invasão soviética do Afeganistão.",
    "Como terminou a Guerra Fria?": "Com a queda do Muro de Berlim em 1989 e a dissolução da União Soviética em 1991."
}

# Transforma o dicionário em texto
base_conhecimento = "\n".join([f"- \"{k}\" → \"{v}\"" for k, v in gabaritos.items()])

# Prompt do modelo
template = """
Você é um professor corrigindo provas. Abaixo está um texto extraído da imagem de um aluno, contendo uma pergunta e uma resposta.

Texto extraído:
{texto_imagem}

Você conhece os seguintes pares de pergunta e gabarito:
{base_conhecimento}

1. Identifique qual é a pergunta no texto extraído.
2. Encontre o gabarito correspondente.
3. Compare com a resposta do aluno.
4. Diga apenas "Correto" ou "Errado".
"""

prompt = PromptTemplate(
    input_variables=["texto_imagem", "base_conhecimento"],
    template=template,
)

llm = Ollama(model="llama3:8b")

chain = LLMChain(llm=llm, prompt=prompt)

# Rodar correção
resultado = chain.run({
    "texto_imagem": texto_extraido,
    "base_conhecimento": base_conhecimento
})

# Resultado
print("Texto da imagem:\n", texto_extraido)
print("Correção:", resultado.strip())